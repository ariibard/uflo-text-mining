# Clase 1 Introducci칩n al *Text Mining*

## Objetivo de la clase

En esta clase realizaremos la presentaci칩n de la materia. Se buscar치 introducir el concepto de miner칤a de texto y la diferencia entre datos estructurados y no estructurados. Adem치s, realizaremos ejercicios pr치cticos a trav칠s de R y R Studio

## **Antes de la clase**

### **1. Instal치 R y R Studio**

Descarg치 e instal치 las 칰ltimas versiones de R y RStudio

-   R 4.2.3 o superior: [https://cran.r-project.org](https://cran.r-project.org/)

-   RStudio 2024.04.0 or superior: <https://posit.co/download/rstudio-desktop>

### **2. Paquetes**

Instal치 los siguientes paquetes copiando y pegando el siguiente c칩digo en la consola de RStudio:

``` r

paquetes_lista <- c(
  "tidyverse", "janitor", "esquisse", "tm","wordcloud"
)

install.packages(paquetes_lista)
```

## Presentaci칩n

<iframe src="presentaciones/clase_1/intro_tm.html" width="100%" height="600px">

</iframe>

## Taller

Para la actividad de hoy vamos a trabajar con el libro de **Harry Potter 3 - El prisionero de Azkaban de J.K Rowling**[^clase1-1]

[^clase1-1]: J. K. Rowling . (1999). Harry Potter y el prisionero de Azkaban. Reino Unido: Bloomsbury.

![](www/patronum.png){fig-align="center" width="593"}

### **Cargamos los paquetes**

```{r warning=FALSE, message=FALSE}


library(tidyverse)
library(esquisse)
library(janitor)
library(tm)
library(wordcloud)
```

#### **Sobre los paquetes**

`Tidyverse` es un맊onjunto de paquetes de R. Se utiliza para analizar datos y est치 compuesto por paquetes que comparten una filosof칤a de dise침o, gram치tica y estructura. M치s informaci칩n [ac치](https://www.tidyverse.org/)

![Fuente: https://x.com/RosanaFerrero/status/1521396654829617153/photo/1](www/tidyverse.jpg){fig-align="center"}

`esquisse` es un paquete que permite generar graficos con `ggplot` a partir de una manera interactiva utilizando drag and drop. M치s informaci칩n [ac치](https://dreamrs.github.io/esquisse/)

`janitor` contiene funciones para limpiar y examinar datos. M치s informaci칩n [ac치](https://www.rdocumentation.org/packages/janitor/versions/2.2.1)

### Cargamos el libro

```{r warning=FALSE, message=FALSE}
# Cargamos los datos
hp3 <- readLines("data/hp3.txt")

# Lo convertimos en un solo vector
libro <- paste(hp3, collapse = " ")

# Vemos los primeros caracteres
print(substr(libro, 1, 500))  




```

#### 쮺uantos caracteres tiene el libro?

```{r}

# 쮺uantos caracteres tiene el libro? 
nchar(libro)
```

#### 쮺uantas oraciones tiene el libro?

```{r}
oraciones <- unlist(str_split(libro, "(?<=[.!?])\\s+"))
length(oraciones)
```

### Frecuencia de palabras m치s utilizadas

#### Limpiamos el texto

`gsub()` es una funci칩n en **R** que se usa para **buscar y reemplazar texto** dentro de cadenas de caracteres.

La sintaxis es:

``` r
gsub("patr칩n_a_buscar", "nuevo_texto", texto)
```

A trav칠s de esta funci칩n vamos a limpiar el texto del libro para mejorar el conteo de las palabrbas

```{r}
# Convertimos a minusculas
libro_limpio <- tolower(libro)  
# Eliminamos las puntuaciones
libro_limpio <- gsub("[[:punct:]]", "", libro_limpio)  
# Eliminamos los n칰meros
libro_limpio <- gsub("[[:digit:]]", "", libro_limpio) 
# Eliminamos espacios m칰ltiples
libro_limpio <- gsub("\\s+", " ", libro_limpio) 
libro_limpio <- gsub("[^\x20-\x7E]", "", libro_limpio)  # Elimina caracteres no imprimibles

```

#### Dividimos las palabras

```{r}
# Divido las palabras:

palabras <- unlist(strsplit(libro_limpio, "\\s+")) 

```

#### Eliminamos las stopwords

Las stopwords (o palabras vac칤as) son palabras muy comunes en un idioma que suelen tener poco valor en an치lisis de texto porque no aportan significado relevante. Ejemplos en espa침ol incluyen:

游댳 Preposiciones: "de", "a", "con", "por", "para" 游댳 Art칤culos: "el", "la", "los", "las" 游댳 Conjunciones: "y", "o", "pero", "aunque" 游댳 Pronombres: "yo", "t칰", "칠l", "ella", "nosotros" 游댳 Verbos auxiliares: "ser", "estar", "haber"

```{r}
stopwords_es <- stopwords("es") 

# Vector sin los stopwords
palabras_filtradas <- palabras[!palabras %in% stopwords_es] 
```

#### Contamos

```{r}
frecuencia <- table(palabras_filtradas)
# Ordenamos por la frecuencia
frecuencia <- sort(frecuencia, decreasing = TRUE) 

# Top 20 palabras
head(frecuencia, 20)
```

### Graficamos

1)  Convertimos nuestras frecuencias en una tabla

```{r}
df_frec <- as.data.frame(frecuencia)
colnames(df_frec) <- c("Palabra", "Frecuencia")


head(df_frec)
```

Me quedo con las 20 palabras m치s mencionadas y grafico utilizando `esquisser`

```{r}

df_grafico <- df_frec |> 
  head(20)


```

``` r
esquisser(df_grafico)
```

Lo dise침amos a gusto y luego guardamos el c칩digo

```{r}

# Grafico final

ggplot(df_grafico) +
  aes(x = Palabra, y = Frecuencia) +
  geom_col(fill = "#440154") +
  labs(
    x = "Palabras",
    y = "Cantidad",
    title = "Palabras mas mencionadas en Harry Potter 3"
  ) +
  ggthemes::theme_fivethirtyeight() +
  theme(
    legend.justification = "top",
    plot.title = element_text(size = 14L,
    face = "bold",
    hjust = 0.5)
  )
```

#### Nube de palabras

Tambi칠n podemos realizar una nube de palabras:

```{r}

wordcloud(names(frecuencia), frecuencia, max.words = 100, colors = brewer.pal(8, "Dark2"))
```
