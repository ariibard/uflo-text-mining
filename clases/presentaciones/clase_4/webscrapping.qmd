---
format:
  revealjs:
    echo: true
    theme: custom.scss
    code-line-numbers: true
embed-resources: true
---

# ğŸš€ Raspado web (web-scrapping)

## ğŸ” Â¿QuÃ© es?

Es una tÃ©cnica que permite extraer informaciÃ³n de distintos sitios web.

Un **scraper** es un programa que **simula el comportamiento de un usuario** navegando por una pÃ¡gina web, pero en lugar de mostrar el contenido, **extrae los datos automÃ¡ticamente**.

âš ï¸ Â¡AtenciÃ³n! Cuando involucra datos personales, plantea desafÃ­os legales y Ã©ticos.

## ğŸ” ProtecciÃ³n de datos personales

-   ğŸ›ï¸ En Argentina, **la Ley 25.326 de ProtecciÃ³n de Datos Personales** protege la informaciÃ³n de los individuos.

-   ğŸŒ Incluso si los datos son "**pÃºblicos**" en redes sociales o sitios web, siguen estando sujetos a **normativas de privacidad.**

## ğŸ” ProtecciÃ³n de datos personales

-   ğŸš« El webscraping sin consentimiento puede constituir una violaciÃ³n de derechos.

-   ğŸ“‹ **Toda base de datos con datos personales debe estar registrada** en la Agencia de Acceso a la InformaciÃ³n PÃºblica (AAIP).

## âš ï¸ Riesgos de la ExtracciÃ³n Masiva de Datos

-   ğŸ£ **Ciberataques dirigidos** (fraudes y phishing)

-   ğŸ†” **UsurpaciÃ³n de identidad**

-   ğŸ•µï¸â€â™‚ï¸ **Vigilancia y perfilado** (reconocimiento facial)

-   ğŸ’° **Reventa de informaciÃ³n** (comercializaciÃ³n de datos)

-   ğŸ”“ **PÃ©rdida de control de la privacidad**

## ğŸ“œ Documentos sobre aspectos normativos y Ã©ticos del webscrapping

-   Agencia de Acceso a la InformaciÃ³n PÃºblica (AAIP). (2023). *DeclaraciÃ³n conjunta sobre webscraping y protecciÃ³n de la privacidad.* [Documento en lÃ­nea](https://www.argentina.gob.ar/sites/default/files/declaracion_conjunta_aaip_datascraping.pdf).

-   Corte Suprema de Justicia de la NaciÃ³n. (2025). Nuevas tecnologÃ­as: Responsabilidad de los buscadores de internet. [Documento en lÃ­nea](https://sj.csjn.gov.ar/homeSJ/notas/nota/189/documento)

## ğŸ“œ Documentos sobre aspectos normativos y Ã©ticos del webscrapping

-   Office of the Privacy Commissioner of Canada (OPC). (2024). *Joint statement on data scraping and the protection of privacy.* [DeclaraciÃ³n en lÃ­nea](https://www.priv.gc.ca/en/opc-news/speeches-and-statements/2024/js-dc_20241028/).

-   Information Commissioner's Office (ICO). (2024). *ICO consultation series on generative AI and data protection.* [Consulta en lÃ­nea](https://ico.org.uk/about-the-ico/ico-and-stakeholder-consultations/ico-consultation-series-on-generative-ai-and-data-protection/).

# Aprender a scrapear

## ğŸŒ Â¿QuÃ© es el HTML de una pÃ¡gina web ?

El HTML (HyperText Markup Language) es el lenguaje que estructura el contenido de las pÃ¡ginas web. Cuando entrÃ¡s a un sitio, tu navegador descarga este cÃ³digo y lo muestra de forma visual.

``` html
<html>
  <head>
    <title>Ejemplo titulo</title>
  </head>
  <body>
    <h1>Ejemplo H1s</h1>
    <p class="destacado">blablablabla.</p>
  </body>
</html>
```

## Â¿ CÃ³mo scrapear?

Hay dos formas de scrapear:

1)  HTMLs `estaticos` que no necesitan interactividad
2)  Necesidad de `interactividad` porque por ejemplo hay que apretar botones.

## ğŸš€Pasos

1.  **Solicita la pÃ¡gina** ğŸŒ Descarga el cÃ³digo HTML desde la web

2.  **Interpreta el cÃ³digo** ğŸ” Encuentra los elementos relevantes (tÃ­tulos, imÃ¡genes, precios, etc.).

3.  **Extrae la informaciÃ³n** ğŸ“Š Guarda los datos en una estructura como un **DataFrame de R**, un **CSV** o una **base de datos**.

# **rvest**: Scraping EstÃ¡tico (HTML)

La documentaciÃ³n del paquete se encuentrÃ¡ [en este link](https://github.com/tidyverse/rvest)

## `rvest`

::: incremental
-   ğŸ“œ **Tipo de scraping:** Obtiene datos directamente del cÃ³digo HTML de una pÃ¡gina web.

-   âš¡ **Velocidad:** RÃ¡pido, porque solo descarga el HTML sin necesidad de renderizar JavaScript.

-   âŒ **Limitaciones:** No puede interactuar con pÃ¡ginas que cargan contenido dinÃ¡mico

-   âœ… **Ideal para:** Sitios con HTML estÃ¡tico, como noticias, blogs o pÃ¡ginas gubernamentales.
:::

## Manos a la obra

::::: columns
::: {.column width="50%"}
![](images/boletin_oficial.png)
:::

::: {.column width="50%"}
Obtener un reporte con la legislaciÃ³n que sale a nivel nacional diariamente. Para ello, vamos a armar un [`scraper del BORA`](https://www.boletinoficial.gob.ar/seccion/primera)
:::
:::::

## 1) Leemos el HTML

ğŸ”¹ 1. `read_html()`â€“ descarga el cÃ³digo HTML de una pÃ¡gina web

Ahora, pagina contiene el HTML de la web y podemos extraer informaciÃ³n de ella.

```{r}
library(rvest) # para scrapear
library(tidyverse) # para modelar
library(gt) # para las tablitas

url <- "https://www.boletinoficial.gob.ar/seccion/primera"
pagina <- read_html(url)


```

## Â¿QuÃ© es lo que necesito descargar?

Voy a observar la pÃ¡gina y listar quÃ© me gustarÃ­a consolidar en mi dataset

:::::: columns
::: {.column width="30%"}
![](https://i.pinimg.com/originals/35/ec/d0/35ecd0734d233cb22f0307fdbe5ab0f4.gif)
:::

:::: {.column width="70%"}
::: incremental
1)  Fecha de hoy
2)  La Ã³rbita del mismo (Ej. Ministerio de economÃ­a)
3)  El nÃºmero de normativa
4)  El nÃºmero de expediente
5)  El enlace de la normativa
:::
::::
::::::

## Fecha de hoy

La mejor forma de **conocer** que **item** del html necesito traerme para poder armar mi base de datos es seleccionando `inspeccionar` al hacer click derecho sobre lo que quiero extraer.

## Inspeccionar elemento

![](images/fecha_hoy.png)

## Fecha de hoy

Eso va a abrir una ventana con el contenido `html` de ese elemento. En este caso `h6.text-primary-alt.text-bold` es un comando CSS. Estos selectores son usados para aplicar estilos a elementos

![](images/fecha_hoy_elementos.png)

## html_nodes()

Esta funciÃ³n encuentra elementos en la pÃ¡gina web usando selectores CSS. Vamos a buscar todos los elementos con la clase *h6.text-primary-alt.text-bold*. `html_node()` solo selecciona el primer elemento

â• Vemos que la fecha se encuentra en el item \[2\]

```{r}
fechas_nodos <- pagina %>% html_nodes("h6.text-primary-alt.text-bold")
fechas_nodos
```

## html_text()

Extrae el texto de un nodo HTML y lo "limpia"

Â¡Ya tenemos nuestro primer objeto escrapeado!

```{r}
fecha_texto <- fechas_nodos[2] %>% html_text(trim = TRUE)
fecha_texto
```

## Ministerio

![](images/ministerio_elemento.png)

## Ministerio / Ã“rbita

Usamos `p.clase` cuando el elemento es una etiqueta 'p' (pÃ¡rrafo).

```{r}

orbitas <- pagina %>% html_nodes("p.item") %>% html_text()
orbitas


```

## Normativas

![](images/fecha_hoy_elementos.png){fig-align="center"}

## Normativas

AcÃ¡ tenemos un problema que es que ambos items (normativa + descripciÃ³n del nÃºmero de expedientes) tienen el mismo formato

```{r}

normativas <- pagina %>% html_nodes("p.item-detalle small") %>% html_text(trim = TRUE)
head(normativas)

```

## Normativas

```{r}
# Me quedo con los nÃºmeros impares que serÃ­an los nÃºmeros de normativa
numeros_normativa <- normativas[seq(1, length(normativas), by = 2)]
numeros_normativa
# Los nÃºmeros pares serian los nÃºmeros de expediente
nro_expediente <- normativas[seq(2, length(normativas), by = 2)]
```

## html_attr()

Algunas veces, la informaciÃ³n no estÃ¡ en el texto, sino en los atributos de la etiqueta HTML. En este caso necesitamos traernos los links

```{r}
enlaces <- pagina %>% html_nodes("a") %>% html_attr("href") 
enlaces

```

## Links de normativa

Hay mÃ¡s links que normativas. Por lo que necesitamos quedarnos **SOLO** con los que tienen la estructura de un link de normativa y eliminar los links de los anexos

![](images/links.png)

## Links de normativa

Nos quedamos solo con los links de de detalle aviso y eliminamos los links a los anexos

```{r}
enlaces_normativa <- enlaces[grepl("/detalleAviso", enlaces) & !grepl("anexos=", enlaces)]
enlaces_normativa
```

## Dataset final

```{r}

df_normativas <- data.frame(Normativa = numeros_normativa,nro_expediente, orbitas,enlaces_normativa, stringsAsFactors = FALSE) |> 
  mutate(fecha_publicacion = fecha_texto) 

df_normativas |> 
  gt()
```

## Â¿Ven algo raro en los links? 

```{r}
df_normativas |> 
  gt()
```


## Agregamos el path completo

```{r}
df_normativas <- df_normativas |> 
  mutate(enlaces_normativa = paste0("https://www.boletinoficial.gob.ar", enlaces_normativa))

df_normativas |> 
  gt()
```

# Â¿Y si quisieramos analizar el contenido de cada normativa? 

# Â¿QuÃ© deberÃ­amos hacer?

## Tratamos de traer el texto de una sola normativa

Para ello nos quedamos con un solo link

```{r}
link_normativa_ejemplo <- df_normativas |> 
  head(1) |> 
  pull(enlaces_normativa)


link_normativa_ejemplo
```


## 1Â° traemos el HTML
Un Ã©xito! Estaban OK los links que sustrajimos de la pÃ¡gina web del BORA

```{r}
texto_normativa <- read_html(link_normativa_ejemplo)

texto_normativa %>%
  html_nodes("#cuerpoDetalleAviso") %>%  # Selecciona el div con ese ID
  html_text(trim = TRUE) 
```

## 3Â° Aplicamos los mismos pasos dentro de un bucle

```r
links_normativas <- df_normativas |> 
  pull(enlaces_normativa)

# Armo un dataset vacÃ­o
base_texto_normativa <- data.frame()

for (i in links_normativas) {
  link <- i
  
  html_normativa <- read_html(link_normativa_ejemplo)
  
  texto_normativa <- html_normativa %>%
  html_nodes("#cuerpoDetalleAviso") %>%  # Selecciona el div con ese ID
  html_text(trim = TRUE) 
  
  df_temp <- data.frame(enlaces_normativa = link, texto_normativa, stringsAsFactors = FALSE) 
  
  base_texto_normativa <- base_texto_normativa |> 
    bind_rows(df_temp)
  
}


```
```{r include = FALSE}
base_texto_normativa <- readRDS("base_texto_normativa.rds")
```

## 4 Â° unimos todo y guardamos

```{r}
df_normativas_final <- df_normativas |> 
  left_join(base_texto_normativa) 

# Guardamos
saveRDS(df_normativas_final, "df_normativas_final.rds")

# Observamos
df_normativas_final |> 
  head(1) 

```


# Recreo

> Volvemos en 10 minutos para comenzar con el taller 

![](https://i.pinimg.com/originals/10/d2/05/10d205b912352788a8b7116a43c00230.gif){fig-align="center" style="border-radius: 100%;"}



