---
format:
  revealjs:
    echo: true
    theme: custom.scss
    code-line-numbers: true
embed-resources: true
---

# Preprocesamiento de Texto en R

# TokenizaciÃ³n, lematizaciÃ³n, limpieza y eliminaciÃ³n de ruido textual

## Objetivos de la clase

::: incremental
-   Comprender el proceso de preprocesamiento de texto para anÃ¡lisis.
-   Aplicar tokenizaciÃ³n, limpieza, stopwords, lematizaciÃ³n y stemming en R.
-   Explorar un corpus real de debates presidenciales
:::

## Â¿Por quÃ© preprocesar?

El texto, a diferencia de los datos estructurados, requiere pasos previos para convertirlo en representaciones analizables (vectores).

## ğŸ“š Â¿QuÃ© significa â€œrepresentaciones analizables (vectores)â€?

Cuando hablamos de r**epresentaciones analizables** en el contexto del anÃ¡lisis de texto, nos referimos a transformar el texto en una forma que las computadoras puedan entender, comparar y procesar matemÃ¡ticamente.

Y eso, en general, significa convertir el texto en `vectores`.

## ğŸ§  Â¿QuÃ© es un vector en este contexto?

Un **vector** es simplemente una lista ordenada de nÃºmeros. En el caso del anÃ¡lisis de texto, un vector representa un documento como una secuencia de nÃºmeros que reflejan cosas como:

## ğŸ§  Â¿QuÃ© es un vector en este contexto?

::: incremental
-   cuÃ¡ntas veces aparece cada palabra en ese texto (frecuencia),
-   si una palabra aparece o no (presencia/ausencia),
-   quÃ© tan importante es esa palabra en comparaciÃ³n con todo el corpus.
:::

## Ejemplo

Supongamos que queremos recolectar discursos que contengan estas palabras:

`["salud", "educaciÃ³n", "derecho", "trabajo"]`

. . .

"El acceso a la salud es un derecho"

## Ejemplo

Supongamos que queremos recolectar discursos que contengan estas palabras:

`["salud", "educaciÃ³n", "derecho", "trabajo"]`

<p><em>"El acceso a la [salud]{style="background-color:#FFA500;"} es un [derecho]{style="background-color:#FFA500;"}"</em></p>

## Ejemplo

`["salud", "educaciÃ³n", "derecho", "trabajo"]`

<p><em>"El acceso a la [salud]{style="background-color:#FFA500;"} es un [derecho]{style="background-color:#FFA500;"}"</em></p>

El vector que representa el texto serÃ­a: `[1, 0, 1, 0]`

. . .

::: incremental
-   Aparece â€œsaludâ€ â†’ âœ…
-   No aparece â€œeducaciÃ³nâ€ â†’ âŒ
-   Aparece â€œderechoâ€ â†’ âœ…
-   No aparece â€œtrabajoâ€ â†’ âŒ
:::

## ğŸ” Â¿Para quÃ© sirve?

Una vez que tenÃ©s un vector, podÃ©s:

::: incremental
-   calcular similitudes entre documentos (medidas de distancia),

-   entrenar modelos de clasificaciÃ³n o predicciÃ³n,

-   visualizar tendencias (ej: con anÃ¡lisis de componentes principales),

-   hacer clustering (agrupamientos),

-   aplicar cualquier tÃ©cnica de machine learning que necesita datos numÃ©ricos.
:::

# Â¿Y cÃ³mo llegamos a eso?

con el **preprocesamiento de texto** que nos ayuda a convertir textos desordenados en vectores organizados listos para anÃ¡lisis.

# TokenizaciÃ³n

## ğŸ§©  Â¿QuÃ© es la tokenizaciÃ³n?

> âœ‚ï¸ **Tokenizar** un texto significa dividirlo en unidades mÃ¡s pequeÃ±as llamadas **tokens**.

En general, los tokens son **palabras**, pero tambiÃ©n pueden ser **frases, oraciones o caracteres**.

## ğŸ§© Â¿Para quÃ© sirve?

::: incremental
-   Convierte texto en bruto en una estructura manejable.\
-   Permite contar palabras, detectar temas y patrones.\
-   Es clave para transformar texto en **vectores analizables**
-   ğŸ§  Sin tokenizaciÃ³n, no se puede hacer minerÃ­a de texto ni anÃ¡lisis estadÃ­stico del lenguaje.
:::

## ğŸ§©  Ejemplo

> *"El acceso a la salud es un derecho"*

Tokenizado por palabras:

::::: columns
::: {.column width="50%"}
- "el" 
- **"acceso"**
- "la"
:::

::: {.column width="50%"}
- **"salud"**
- "es"
- "un"
- **"derecho"**
:::
:::::

## ğŸ§©  Â¿CÃ³mo se aplica en R?

`unnest_tokens()` â†’ separa en palabras

```{r}
library(dplyr)
library(tidytext)
# Simulamos una tabla con texto
textos <- tibble(id = 1, texto = "El acceso a la salud es un derecho")
# TokenizaciÃ³n
tokens <- textos %>%
  unnest_tokens(output = palabra, input = texto)
tokens
```

## ğŸ§©  Â¿CÃ³mo se aplica en R?

-   `get_stopwords(language = "es")` â†’ trae una lista predefinida de palabras vacÃ­as en espaÃ±ol

-   `anti_join()` â†’ se queda solo con las palabras que no estÃ¡n en la lista de stopwords

## ğŸš« Stopwords

Las stopwords son palabras muy comunes en un idioma que, por su alta frecuencia y bajo contenido semÃ¡ntico, suelen eliminarse del anÃ¡lisis. Ejemplos: el, la, de, en, y, a, que. 

[Eliminarlas permite que el anÃ¡lisis se enfoque en las palabras mÃ¡s informativas.]{style="background-color:#FFA500;"}

## ğŸ§©  Â¿CÃ³mo se aplica en R?

```{r}
stopwords_es <- get_stopwords(language = "es") 

# Simulamos una tabla con texto
textos <- tibble(id = 1, texto = "El acceso a la salud es un derecho")

# TokenizaciÃ³n
tokens <- textos %>%
  unnest_tokens(output = palabra, input = texto)%>%
  anti_join(stopwords_es, by = c("palabra" = "word"))

tokens
```

## ğŸ§© Otras opciones

``` r
unnest_tokens(output, input, token = "words")      # palabras
unnest_tokens(output, input, token = "sentences")  # oraciones
unnest_tokens(output, input, token = "characters") # letras
unnest_tokens(output, input, token = "ngrams", n = 2)  # bigramas
```

# ğŸ§¹ Limpieza

## ğŸ§¹ Limpieza: Â¿QuÃ© es?

Es el conjunto de acciones para eliminar elementos "ruidosos" del texto: puntuaciÃ³n, nÃºmeros, mayÃºsculas, caracteres especiales, URLs, espacios en blanco, etc.

Muchos de estos elementos no aportan informaciÃ³n relevante para el anÃ¡lisis del contenido del texto. Por ejemplo, la coma o los signos de exclamaciÃ³n no suelen ser Ãºtiles para saber de quÃ© trata un texto.

## ğŸ§¹ Limpieza: Â¿Por quÃ© es Ãºtil?

Reduce el "**ruido**" en el anÃ¡lisis, mejora los resultados y hace mÃ¡s eficiente el procesamiento posterior. AdemÃ¡s, ayuda a normalizar el texto (por ejemplo, convertir todo a minÃºsculas evita que R distinga entre `Salud` y `salud` como si fueran cosas distintas).

## ğŸ§¹ Â¿CÃ³mo limpiar texto en R?

Vamos a utilizar la librerÃ­a `{stringr}` que tiene funciones para manipulaciÃ³n de texto *(muchas las vimos en la clase nÂ° 2)*

```{r}
library(stringr)
library(stringi)
```

## ğŸ§¹ Â¿CÃ³mo limpiar texto en R?

```{r}
texto_sucio <- "ğŸ—£ï¸ Â¡Hola! Este es un ejemplo de texto con RUIDO: nÃºmeros (12345), sÃ­mbolos $$$, @correos.com, http://link.com, #hashtags, signos!!! Â¿Â¡y tildes? ÃÃ‰ÃÃ“Ãš..."

df <- tibble(texto = texto_sucio)
```

## ğŸ§¹ MinÃºsculas y mayÃºsculas

```{r}
df <- df %>%
  mutate(texto = str_to_lower(texto))

print(df$texto)

df <- df %>%
  mutate(texto = str_to_upper(texto))

print(df$texto)
```

## ğŸ§¹ Eliminamos URLs

-   `str_remove_all()` elimina todo lo que coincide con determinado patrÃ³n

La clave: `expresiones regulares`

```{r}
df_limpio <- df %>%
  # Convertimos todo a minÃºsculas
  mutate(texto = str_to_lower(texto)) %>%  
  # Eliminamos URLs
  mutate(texto = str_remove_all(texto, "http[s]?://\\S+"))

print(df_limpio$texto)
```

## ğŸ§¹ Eliminamos menciones

```{r}
df_limpio <- df_limpio %>%
  # Menciones
  mutate(texto = str_remove_all(texto, "@\\w+")) |> 
  # Hashtags
  mutate(texto = str_remove_all(texto, "#\\w+")) 

print(df_limpio$texto)
```

## ğŸ§¹ Signos de puntuaciÃ³n

```{r}
df_limpio <- df_limpio %>%
  # Signos de puntuaciÃ³n
  mutate(texto = str_remove_all(texto, "[[:punct:]]"))
  
print(df_limpio$texto)
```

## ğŸ§¹ NÃºmeros

```{r}
df_limpio <- df_limpio %>%
  # Signos de puntuaciÃ³n
  mutate(texto = str_remove_all(texto, "[[:digit:]]"))
  
print(df_limpio$texto)
```

## ğŸ§¹ Espacios en blanco

1)  La funciÃ³n `str_squish()` elimina espacios consecutivos
2)  Reemplaza todos los espacios consecutivos (como varios espacios, tabs o saltos de lÃ­nea) por un solo espacio " " pero

```{r}
df_limpio <- df_limpio %>%
  # Espacios
  mutate(texto = str_squish(texto)) |> 
  # Otra opcion con expresiones regulares:
  mutate(texto = str_replace_all(texto, "\\s+", " "))

print(df_limpio$texto)
```

## ğŸ§¹ Espacios en blanco

1)  La funciÃ³n `str_trim()` elimina espacios al principio y al final del texto
2)  Otras opciones son: `stri_trim_both()`, `stri_trim_left()`, `stri_trim_right()` eliminan espacios al inicio y/o final del texto.

```{r}
df_limpio <- df_limpio %>%           
  mutate(texto = str_trim(texto))

print(df_limpio$texto)
```

## ğŸ§¹ Tildes

1)  La funciÃ³n `str_trim()` elimina espacios al principio y al final del texto

```{r}
df_limpio <- df_limpio %>%                                 
  mutate(texto = stri_trans_general(texto, "Latin-ASCII"))

print(df_limpio$texto)
```

## ğŸ§¹ Eliminar emojis

```{r}
df_limpio <- df_limpio %>% 
  mutate(texto = stri_replace_all_regex(texto, "\\p{So}", ""))

print(df_limpio$texto)
```

## ğŸ§¹ Eliminar simbolos

```{r}

df_limpio <-  df_limpio %>% 
  mutate(texto = stri_replace_all_regex(texto,"\\p{Sc}", ""))

print(df_limpio$texto)
```


# ğŸŒ± Stemming

## ğŸŒ± Â¿QuÃ© es Stemming?

Es un proceso que reduce una palabra a su raÃ­z gramatical. Por ejemplo, caminando, camina, caminamos se reducen a camin. Permite grupar diferentes formas de una misma palabra bajo una forma base comÃºn, sin importar la conjugaciÃ³n o el gÃ©nero

## ğŸŒ± Â¿CÃ³mo se usa en R?

`wordStem()` del paquete `{SnowballC}` aplica un algoritmo para reducir palabras a su raÃ­z gramatical, ignorando conjugaciones, plurales, gÃ©neros, etc.

```{r}
library(SnowballC)

textos <- tibble(id = 1, texto = "Caminando caminamos caminÃ© camina")

tokens <- textos %>%
  unnest_tokens(output = palabra, input = texto)

```

## ğŸŒ± Â¿CÃ³mo se usa en R?

```{r}
tokens
```
## ğŸŒ± Â¿CÃ³mo se usa en R?

```{r}
tokens_raiz <- tokens %>%
  mutate(raiz = wordStem(palabra, language = "spanish"))

tokens_raiz
```

# ğŸ§  LematizaciÃ³n

Es un proceso similar al stemming, pero mÃ¡s "inteligente": en lugar de cortar la palabra, busca devolver su forma canÃ³nica o de diccionario (lema). Ejemplo: corriendo â†’ correr. 

Para mantener el sentido lingÃ¼Ã­stico correcto. A diferencia del stemming, no se pierde la forma reconocible de la palabra.

## ğŸ§   Â¿CÃ³mo se usa en R? 

```{r}

library(udpipe)
ejemplo <- c("somos", "soy", "seremos")
prueba <- udpipe(ejemplo, "spanish")

prueba[, c("token", "lemma", "upos")]
```

## â—Limitaciones de algunos paquetes

- Muchos paquetes en R, como `udpipe`, estÃ¡n entrenados principalmente para el **inglÃ©s**.
- Por eso, si le das verbos o palabras en espaÃ±ol, puede que **no los reconozca** o no devuelva su lema correctamente.
- No da error, pero **devuelve la palabra tal cual**.

# Recreo

> Volvemos en 10 minutos para comenzar con el taller

![](https://i.pinimg.com/originals/10/d2/05/10d205b912352788a8b7116a43c00230.gif){fig-align="center" style="border-radius: 100%;"}
