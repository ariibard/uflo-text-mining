---
format:
  revealjs:
    echo: true
    theme: custom.scss
    code-line-numbers: true
    
embed-resources: true
revealjs-plugins:
  - codewindow
---

# Analisis de sentimiento y medidas de similitud

## Analizar el contenido emocional {.smaller}

Podemos utilizar las herramientas de miner√≠a de texto para analizar el contenido emocional del texto mediante programaci√≥n

En el an√°lisis de sentimiento se suelen distinguir dos grandes enfoques:

1.  Enfoque l√©xico (basado en diccionarios)
2.  Enfoque basado en clasificaci√≥n autom√°tica

# Enfoque l√©xico {.smaller}

Una forma de analizar el sentimiento de un texto es considerarlo como una combinaci√≥n de sus palabras individuales y el contenido sentimental del texto completo como la suma del contenido sentimental de cada palabra. Se analiza el texto buscando qu√© palabras est√°n en ese diccionario y se calcula un promedio de sentimiento

‚úÖ Ventajas: f√°cil de interpretar, r√°pido, transparente.

‚ùå Desventajas: no capta contexto, iron√≠a, negaciones o intensificadores (ej: "no est√° nada mal").

## Enfoque Clasificaci√≥n Autom√°tica {.smaller}

Este segundo m√©todo usa t√©cnicas de aprendizaje autom√°tico: se entrena un modelo con textos previamente clasificados por humanos (como "positivo", "negativo", "neutral") para que aprenda patrones de lenguaje que predicen el sentimiento, incluso cuando no aparecen palabras expl√≠citamente ‚Äúpositivas‚Äù o ‚Äúnegativas‚Äù.

‚úÖ Ventajas: capta contexto, negaciones, matices.

‚ùå Desventajas: requiere muchos datos, mayor complejidad t√©cnica y computacional.

# 1. LEXICONES

## Los sentimientos

El paquete `tidytext` proporciona acceso a varios l√©xicos de sentimiento

-   `AFINN`de [Finn √Örup Nielsen](http://www2.imm.dtu.dk/pubdb/views/publication_details.php?id=6010) ,

-   `bing`de [Bing Liu y colaboradores](https://www.cs.uic.edu/~liub/FBS/sentiment-analysis.html) , y

-   `nrc`de [Saif Mohammad y Peter Turney](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm) .

## Lexicones

Estos tres l√©xicos se basan en unigramas, es decir, palabras individuales. Contienen muchas palabras en **ingl√©s** y se les asigna una puntuaci√≥n seg√∫n su sentimiento positivo o negativo, y tambi√©n, posiblemente, emociones como alegr√≠a, ira, tristeza, etc

## ¬øQu√© pasa en espa√±ol?

La mayor√≠a de los modelos y paquetes de an√°lisis de sentimiento est√°n entrenados en ingl√©s.

üëâ Por eso, en esta clase:

-   Usamos un lexic√≥n traducido (AFINN).
-   Usaremos uno desarrollado por Becerra,G.
-   Uno desarrollado por la UBA (SACAR de SHINY)

# Tango

![](https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExdDZjaGR5ZGQxcG00YTB1Z2hsanE5ajVzdmpxeDBkbzN3emlodm1rZiZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/l2R0azdPUa6MDVbYA/giphy.gif){fig-align="center"}

# ¬øQu√© emociones tienen las letras de tango?

## ¬øQu√© emociones tienen las letras de tango?

[Dataset](https://github.com/gefero/tango_scrap) de German Rosati obtenido a trav√©s de scrapeo web

::: codewindow
```{r}
library(tidyverse)
library(readr)
library(janitor)
url <- "https://raw.githubusercontent.com/gefero/tango_scrap/master/Data/Todo_Tango_letras_final.csv"
tango <- read_csv(url) |> 
  clean_names() |> 
  # Elimino los que no tienen letra
  drop_na(letra)
```
:::

# ¬øC√≥mo lo hacemos?

![](imagenes/tidytext.jpg){fig-align="center" width="206"}

## 1. Traemos los lexicones

Empezamos por el lexic√≥n de Becerra, G. 

Si observamos el mismo tiene un puntaje. Ese es el que usaremos para clasificar las letras de tango. 

::: codewindow
```{r}
lexicones <- readr::read_csv('https://raw.githubusercontent.com/gastonbecerra/curso-intro-r/main/data/lexicones.csv')

head(lexicones)
```

:::

## 2. Lematizamos nuestro corpus de texto

Esto es para poder unirlo con los lexicones y su puntaje. Para ello vamos a utilizar la librer√≠a `{udpipe}`

```{r}
library(udpipe)
#ud_model <- udpipe_download_model(language = "spanish")
ud_model <- udpipe_load_model(ud_model$file_model)
anotado <- udpipe_annotate(ud_model, x = tango$letra, doc_id = tango$link)
anotado_df <- as_tibble(anotado)

anotado_df %>%
  select(doc_id, token, lemma)
```

```{r echo = FALSE}
saveRDS(anotado_df %>%
  select(doc_id, token, lemma), "lemas.rds")

load("lemas.rds")
```

